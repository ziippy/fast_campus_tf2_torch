{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "467ef593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b074a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_cuda = False\n",
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd864065",
   "metadata": {},
   "source": [
    "## Data Define - using DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2868c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziippy/venv_tf2/lib/python3.8/site-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "                datasets.MNIST('dataset/', train=True, download=True, \n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                              ])),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "                datasets.MNIST('dataset/', train=False, \n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize(mean=(0.5,), std=(0.5,))\n",
    "                              ])),\n",
    "                batch_size=test_batch_size,\n",
    "                shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b0e206",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # feature extraction\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        # fully-connected\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "263b0f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdc8bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c26e118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ziippy/venv_tf2/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 0/60000 (0%)\tLoss: 2.311277\n",
      "Train Epoch: 1 6400/60000 (11%)\tLoss: 2.293156\n",
      "Train Epoch: 1 12800/60000 (21%)\tLoss: 2.279752\n",
      "Train Epoch: 1 19200/60000 (32%)\tLoss: 2.276142\n",
      "Train Epoch: 1 25600/60000 (43%)\tLoss: 2.239128\n",
      "Train Epoch: 1 32000/60000 (53%)\tLoss: 2.232791\n",
      "Train Epoch: 1 38400/60000 (64%)\tLoss: 2.202166\n",
      "Train Epoch: 1 44800/60000 (75%)\tLoss: 2.144686\n",
      "Train Epoch: 1 51200/60000 (85%)\tLoss: 2.131424\n",
      "Train Epoch: 1 57600/60000 (96%)\tLoss: 2.066348\n",
      "\n",
      "Test set: Average loss: 2.0185, Accuracy: 6961 / 10000 (70%)\n",
      "Train Epoch: 2 0/60000 (0%)\tLoss: 2.009079\n",
      "Train Epoch: 2 6400/60000 (11%)\tLoss: 1.872707\n",
      "Train Epoch: 2 12800/60000 (21%)\tLoss: 1.658992\n",
      "Train Epoch: 2 19200/60000 (32%)\tLoss: 1.597974\n",
      "Train Epoch: 2 25600/60000 (43%)\tLoss: 1.400004\n",
      "Train Epoch: 2 32000/60000 (53%)\tLoss: 1.186932\n",
      "Train Epoch: 2 38400/60000 (64%)\tLoss: 0.966133\n",
      "Train Epoch: 2 44800/60000 (75%)\tLoss: 0.777622\n",
      "Train Epoch: 2 51200/60000 (85%)\tLoss: 0.819548\n",
      "Train Epoch: 2 57600/60000 (96%)\tLoss: 0.685385\n",
      "\n",
      "Test set: Average loss: 0.5614, Accuracy: 8649 / 10000 (86%)\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "log_interval = 100\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    # Train mode\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} {}/{} ({:.0f}%)\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100 * batch_idx / len(train_loader), \n",
    "                loss.item()))\n",
    "    \n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()    \n",
    "            pred = output.argmax(dim=1, keepdim=True)    \n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {} / {} ({:.0f}%)'.format(\n",
    "        test_loss, correct, len(test_loader.dataset), 100 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c231fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
